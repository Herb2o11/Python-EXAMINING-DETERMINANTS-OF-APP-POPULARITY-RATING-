{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMINING DETERMINANTS OF APP POPULARITY/RATING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both AppleStore and Google PLay have millions of apps. How then do you ensure that \n",
    "your app is successful in such a crowded market? It is therefore vital to examine\n",
    "factors that determine app popularity or rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IMPORT THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas and numpy libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read the data and store in variables\n",
    "data = pd.read_csv(\"appleStore_data.csv\", encoding='utf8')\n",
    "desc = pd.read_csv(\"appleStore_description.csv\", encoding='utf8')\n",
    "\n",
    "data.head()\n",
    "desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: PROCESS THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: we can infer information about an app based on the description\n",
    "The longer longer the description, the more detailed the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute length of app description\n",
    "desc[\"desc_len\"] = desc['app_desc'].apply(lambda x: len(x))\n",
    "desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the new desc_len column to the main dataframe (i.e., data)\n",
    "data[\"desc_len\"] = desc[\"desc_len\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the categorical columns in the data\n",
    "data['cont_rating'].value_counts() #gets frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the categorical columns in the data\n",
    "data['prime_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape shows number of rows and columns in the dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unrated apps from the data\n",
    "#select only the rows for which user_rating_ver column values are not 0\n",
    "data = data[data.user_rating_ver !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get summary statistics again\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the shape of the data again\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cont_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prime_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prime_genre, combine categories with fewer values into one category\n",
    "#decision: combine all those with fewer than 100 into one category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the selected categories into a pattern\n",
    "#combined category is \"Other\"\n",
    "to_rep ='|'.join(['Lifestyle','Sports','Shopping','Weather','Travel',\n",
    "                  'Book','Reference','Finance','News','Business',\n",
    "                  'Food & Drink','Navigation','Medical','Catalogs']); \n",
    "\n",
    "#replace those categories with \"Other\"\n",
    "data['prime_genre'] = data['prime_genre'].str.replace(to_rep, 'Other')\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get frequencies again\n",
    "data['prime_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert app size from bytes to megabytes\n",
    "#apply() function is similar to a loop\n",
    "#it takes the lambda expression and performs it on every value of the\n",
    "#column\n",
    "mb = 1048576 #in binary system\n",
    "data['size_mb'] = data['size_bytes'].apply(lambda x: x/mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price = data['price'] #get price variable from dataframe\n",
    "pricing=[] #list variable for pricing\n",
    "\n",
    "#evaluate value in price: if 0, append \"Free\" to pricing, else\n",
    "#append \"Paid\" to pricing\n",
    "for p in price:\n",
    "    if p==0:\n",
    "        pricing.append(\"Free\")\n",
    "    else:\n",
    "        pricing.append(\"Paid\")\n",
    "\n",
    "#append new pricing variable to the dataframe       \n",
    "data['pricing'] = pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get frequencies\n",
    "data['pricing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize rating:\n",
    "data[\"user_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if rating >=4, highly rated=yes, otherwise=0\n",
    "#list variable\n",
    "Highly_rated = []\n",
    "\n",
    "#Highly_rated = data1[\"user_rating\"].apply(lambda x: x>4)\n",
    "\n",
    "rating = data[\"user_rating\"]\n",
    "for rate in rating:\n",
    "    if rate >=4:\n",
    "        Highly_rated.append(\"Yes\")\n",
    "    else:\n",
    "        Highly_rated.append(\"No\")\n",
    "               \n",
    "print(Highly_rated)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append to dataframe\n",
    "data['Highly_rated'] = Highly_rated\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['prime_genre'],data['Highly_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['cont_rating'],data['Highly_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['ipadSc_urls.num'],data['Highly_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify columns to drop and drop them\n",
    "to_drop = ['Unnamed: 0','id','track_name','size_bytes','currency','price','ver','vpp_lic']\n",
    "\n",
    "#drop the specified columns and assign the result to a new dataframe\n",
    "data1 = data.drop(to_drop, axis=1)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical variables into numerical dummy variables\n",
    "#dummy variable assigns 1 for presence of category and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data3 = pd.get_dummies(data1, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform numerical data using log transformation\n",
    "#adjusts values into a comparable scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get numericalo columns\n",
    "num_cols=['rating_count_tot','rating_count_ver','user_rating',\n",
    "          'user_rating_ver','sup_devices.num','ipadSc_urls.num',\n",
    "          'lang.num','size_mb','desc_len']\n",
    "\n",
    "#create a dataframe of numerical columns\n",
    "df_numeric =data3[num_cols]\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply log transformation to numeric columns\n",
    "df_num_log = df_numeric.apply(lambda x: np.log1p(x))\n",
    "df_num_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace dataframe columns value with transformed values for numeric columns\n",
    "data3[num_cols] = df_num_log\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute correlations for continuous variables\n",
    "correl = df_num_log.corr()\n",
    "#print(correl)\n",
    "\n",
    "#import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sns.heatmap(df_log.corr(), annot=True, vmin=-1, vmax=1, center=0, cmap='coolwarm')\n",
    "# Sample figsize in inches\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(correl, annot=True, linewidths=.5, ax=ax, cmap='coolwarm', fmt='.2g', cbar=False, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the correlation coefficients, there are high correlations between rating_count_tot \n",
    "and rating_count_ver (0.66), implying multicollinearity. Similarly, user_rating and \n",
    "user_rating_ver have a high correlation coeffcient of 0.72. These pairs of various should not\n",
    "be used at the same time in analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPE 3: RUN LOGISTIC EXPLANATORY REGRESSION MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate a model to examine factors that influence pricing of the app\n",
    "Exclude all user rating variables (assumption: we want to use only intrinsic features of the app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate explanatory model (models are built to EXPLAIN and to PREDICT)\n",
    "import statsmodels.api as sm  #geared toward explanation rather than prediction\n",
    "\n",
    "#Regression equation: Y = a0 +aiXi + e\n",
    "\n",
    "#specify X and Y variables\n",
    "#rating_count_tot\trating_count_ver\tuser_rating\tuser_rating_ver\n",
    "drop_cols=['prime_genre','sup_devices.num','rating_count_tot','rating_count_ver', \n",
    "           'user_rating_ver', 'user_rating'] \n",
    "\n",
    "\n",
    "X = data3.drop(drop_cols,axis=1)  #use the entire for explanation\n",
    "\n",
    "y = data3['Highly_rated_Yes']\n",
    "\n",
    "\n",
    "X.head()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result=logit_model.fit(fit_intercept=True)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds ratios and 95% CI\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print(np.exp(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLANATORY MODEL RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Model Fit: F-statistic and adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-statistic = 53.18, with p=0; which means that the model is statistically significant and useful\n",
    "in explaining the variation in app rating.\n",
    "\n",
    "However, the coefficient of determination (adjusted R squared) is only 0.147, which implies that\n",
    "14.7% of the variation in app rating is explained by the factors in the model. This is a low\n",
    "value but is typical of cross-section data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Coefficients - significance (siginificant or not) and nature of relationship \n",
    "(Positive or negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#continuous variables\n",
    "ipadSc_urls.num (b=0.0181; p=0) and lang.num (b=0.0107; p=0) are statistically significant and\n",
    "have a positive effect on app rating. For example, a unit increase in the number of pictures \n",
    "of the app increases app rating by 0.018 and a unit increase in the number of supported\n",
    "languages increase app rating by 0.011.\n",
    "\n",
    "#categorical variables - explained in relation to reference category.\n",
    "prime_genre_Games (b=0.0363 ; p=0) is statistically significant and has a positive effect on \n",
    "app rating. It implies that relative to education, an app being of games genre increases rating\n",
    "by 0.036.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managerial implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase overall rating of their apps, developers should focus on proving clear representation\n",
    "of their app features pictorially and also ensure that their app can be used across multiple\n",
    "languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: RUN PREDICTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT ALL THE NECESSARY LIBRARIES\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "#import statmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#split the data\n",
    "#Split the data into 60% training set and 40% test set\n",
    "df_train,df_test=train_test_split(data2,test_size=0.4, random_state=0)\n",
    "df_train.shape\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first install xgboost\n",
    "#!pip install xgboost \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify X and Y variables\n",
    "drop_cols1=['rating_count_ver', 'user_rating_ver', 'user_rating'] \n",
    "\n",
    "\n",
    "X_train = df_train.drop(drop_cols1, axis=1)\n",
    "\n",
    "y_train = df_train['Highly_rated_Yes']\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names of the various classification approaches for easy presentation of the results\n",
    "names = [\"Logististic Regression\", \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"XGBoost\",\"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "scores = [] #list variable to hold classification scores\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=0.001, solver='lbfgs', learning_rate='adaptive', max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipeline = Pipeline(steps=[\n",
    "                      ('classifier', classifier)])\n",
    "    pipeline.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    scores.append(pipeline.score(X_test, y_test))\n",
    "    print(\"model score: %.3f\" % pipeline.score(X_test, y_test))\n",
    "    print(\"\\n -----------------------------------------------------------------------------------\")\n",
    "    \n",
    "#end of pipeline\n",
    "\n",
    "#Create a dataframe for prediction scores\n",
    "scores_df = pd.DataFrame(zip(names,scores), columns=['Classifier', 'Accuracy Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify X and Y variables (test dataste)\n",
    "\n",
    "X_test = df_test.drop(drop_cols1, axis=1)\n",
    "\n",
    "y_test = df_test['user_rating']\n",
    "\n",
    "lr = LinearRegression()  #create linear regression (lr) object\n",
    "\n",
    "#fit using training set\n",
    "#fit the data using the fit() method of lr object (gives coefficients\n",
    "#required for predictions)\n",
    "lr.fit(X_train,y_train) \n",
    "\n",
    "pred_lr = lr.predict(X_test)  #tring to predict y_test\n",
    "\n",
    "#print the RMSE (Assesses the predictive performance of the model)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#Lasso Regression uses regularization parameter (alpha) to improve model performance\n",
    "#Ridge regression: OLS + alpha*summation(abs(coeffs))\n",
    "\n",
    "\n",
    "lasso = Lasso()  #create lasso object\n",
    "\n",
    "parameters = {'alpha':[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 0.1, 1,2,5,10,20]}\n",
    "lasso_regressor = GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "lasso_regressor.fit(X_train,y_train) #fit model using training set\n",
    "\n",
    "print(lasso_regressor.best_params_)\n",
    "#print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction using optimal alpha for lasso model\n",
    "lasso = Lasso(alpha=0.0001)\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "pred_test_lasso = lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression uses regularization parameter (alpha) to improve model performance\n",
    "#Ridge regression: OLS + alpha*summation(squared(coeffs))\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "#select optimal alpha (regularization parameter)\n",
    "alphas = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 0.1, 1,2,5,10,20]\n",
    "\n",
    "ridge_reg = linear_model.RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "\n",
    "ridge_reg.fit(X_train,y_train) #fit the model to genarate the parameters\n",
    "\n",
    "cv_mse = np.mean(ridge_reg.cv_values_,axis=0)\n",
    "print(\"alphas: %s\" % alphas)\n",
    "print(\"CV MSE: %s\" % cv_mse)\n",
    "\n",
    "print(\"Best alpha using built-in RidgeCV: %f\" % ridge_reg.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the prediction using the best model\n",
    "alpha = ridge_reg.alpha_ #transcribe the alpha for the best model\n",
    "ridge_reg = linear_model.Ridge(alpha=alpha)\n",
    "\n",
    "ridge_reg.fit(X_train, y_train) #fit model using training dataset\n",
    "\n",
    "pred_y = ridge_reg.predict(X_test) #maka predictions using the test set\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RMSE statistic, we select a model with the lowest score. Here, OLS model has the lowest\n",
    "score and therefore will be used to make out-of-sample predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Out-of-Sample Predictions with the Best Model\n",
    "(simulate the production environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression is the Best model\n",
    "summary = pd.DataFrame(df_test.describe())\n",
    "print(summary)\n",
    "summary.to_csv('summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Predict the expected enrollment for the following X's:\n",
    "Xnew = pd.read_csv(\"X_new.csv\")\n",
    "Xnew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['rating_count_tot','sup_devices.num','ipadSc_urls.num','lang.num','desc_len',\n",
    "                'size_mb']\n",
    "df_num_new = Xnew[numeric_cols]\n",
    "print(df_num_new)\n",
    "\n",
    "df_num_new_log = df_num_new.apply(lambda x: np.log1p(x))\n",
    "print(df_num_new_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew[numeric_cols] = df_num_new_log[numeric_cols]\n",
    "print(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "ynew = lr.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "#predicted value should be exponentiated because data was log-transformed\n",
    "#print(\"X=%s, Predicted app rating=%s\" % (Xnew, np.exp(ynew)))\n",
    "print(\"Predicted app rating:\", (np.exp(ynew)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the given features of an app, we predict its rating to be a 5, which means \n",
    "an excellent rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(\"data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#logit_model=sm.Logit(y,x_trans)\n",
    "#logit_model=sm.Logit(y,inter)\n",
    "logit_model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "result=logit_model.fit(fit_intercept=True)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d9788b21e20132f45a0b9f05d4c7865bb8e6e0d7c2b528b83da3b6508a642251"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}